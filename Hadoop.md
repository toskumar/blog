# Hadoop
Hadoop is a framework that allows for the distributed storage, processing of large data sets across clusters of computers using simple programming models.

## Ambari
A web-based tool for provisioning, managing, and monitoring Apache Hadoop clusters.
## Avro 
A data serialization system.
## Cassandra
A scalable multi-master database with no single points of failure.
## Chukwa
A data collection system for managing large distributed systems.
## HBase
A scalable, distributed database that supports structured data storage for large tables.
## Hive
A data warehouse infrastructure that provides data summarization and ad hoc querying.
## Mahout
A Scalable machine learning and data mining library.
## Pig
A high-level data-flow language and execution framework for parallel computation.
## Spark
A fast and general compute engine for Hadoop data
## Submarine
A unified AI platform which allows engineers and data scientists to run Machine Learning and Deep Learning workload in distributed cluster.
## Tez
A generalized data-flow programming framework, built on Hadoop YARN, which provides a powerful and flexible engine to execute an arbitrary DAG of tasks to process data for both batch and interactive use-cases.
## ZooKeeper
A high-performance coordination service for distributed applications.
